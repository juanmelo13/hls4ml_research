{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c973caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis_HLS/2021.2/bin' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b456615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "517dc679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4e5cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d0930d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def normalize(image):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255.\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae6aa07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "edb9e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = np.array([normalize(im) for im in list(X_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1f58956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b9471ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a523b719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 9s 10ms/step - loss: 0.6273 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.1888 - val_sparse_categorical_accuracy: 0.9463\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1736 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.1372 - val_sparse_categorical_accuracy: 0.9613\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.0929 - val_sparse_categorical_accuracy: 0.9724\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0787 - val_sparse_categorical_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7e01bd35b0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6142e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: flatten_6_input, layer type: Input\n",
      "Layer name: dense_12, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_12\n",
      "Layer name: dense_13, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_13\n",
      "-----------------------------------\n",
      "Configuration\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: flatten_6_input, layer type: InputLayer, input shapes: [[None, 28, 28]], output shape: [None, 28, 28]\n",
      "Layer name: flatten_6, layer type: Reshape, input shapes: [[None, 28, 28]], output shape: [None, 784]\n",
      "Layer name: dense_12, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 128]\n",
      "Layer name: dense_13, layer type: Dense, input shapes: [[None, 128]], output shape: [None, 10]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "# plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_1/hls4ml_prj',\n",
    "                                                       part='xcu250-figd2104-2L-e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e774805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1db199db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test_norm)\n",
    "y_hls = hls_model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cf44cea6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.3569      4.935482   11.826595    2.6929393 -13.501325   -0.1435949\n",
      "  -2.383676  -10.909       0.4189981 -13.909458 ] [ -4.1904297    4.78125     11.124023     2.477539   -12.692383\n",
      "  -0.19824219  -2.4746094  -10.474609     0.38085938 -13.233398  ]\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(X_test)\n",
    "\n",
    "# pick a sample to plot\n",
    "image = X_test[1]\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(results[1], y_hls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2176eca1",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Vivado HLS installation not found. Make sure \"vivado_hls\" is on PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhls_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml/lib/python3.9/site-packages/hls4ml/model/hls_model.py:722\u001b[0m, in \u001b[0;36mHLSModel.build\u001b[0;34m(self, reset, csim, synth, cosim, validation, export, vsynth)\u001b[0m\n\u001b[1;32m    720\u001b[0m     found \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommand -v vivado_hls > /dev/null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m found \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 722\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVivado HLS installation not found. Make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvivado_hls\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on PATH.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntel\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Vivado HLS installation not found. Make sure \"vivado_hls\" is on PATH."
     ]
    }
   ],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('model_1/hls4ml_prj/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
